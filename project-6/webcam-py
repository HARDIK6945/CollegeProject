from sort import Sort
from ultralytics import YOLO
import cv2
import cvzone
from cvzone.Utils import cornerRect
import math
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Tracker
tracker = Sort(max_age=20, min_hits=3, iou_threshold=0.3)

# Initialize video capture
cap = cv2.VideoCapture("project-6/video/2.mp4")
cap.set(3, 1280)  # Set the width of the frame
cap.set(4, 720)   # Set the height of the frame

# Enable full-screen mode
cv2.namedWindow("Crowd Detection", cv2.WND_PROP_FULLSCREEN)
cv2.setWindowProperty("Crowd Detection", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

# Load YOLOv8 model
model = YOLO('project-6/best.pt')

# Define class names (if needed for reference)
classNames = ['person']  # Replace with actual classes from your trained model

# Set to store all unique IDs
unique_ids = set()

paused = False  # Flag to toggle pause state

while True:
    if not paused:
        success, img = cap.read()
        if not success:
            break  # Exit loop if frame is not captured

        detections = np.empty((0, 5))
        current_frame_ids = set()  # To track IDs present in the current frame

        # Run YOLO model on the captured frame
        results = model(img, stream=True)

        for r in results:
            boxes = r.boxes
            for box in boxes:
                x1, y1, x2, y2 = box.xyxy[0]
                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

                # Draw bounding rectangle using cvzone
                cornerRect(img, (x1, y1, x2 - x1, y2 - y1), l=15, t=2, colorR=(0, 0, 255))  # Red rectangle

                # Confidence of detection
                conf = math.ceil(box.conf[0] * 100) / 100

                # Class index
                cls = int(box.cls[0])

                # Add detection to detections array
                currentarray = np.array([x1, y1, x2, y2, conf])
                detections = np.vstack((detections, currentarray))

        # Update tracker with detections
        resultstracker = tracker.update(detections)

        for result in resultstracker:
            x1, y1, x2, y2, obj_id = map(int, result)  # Ensure values are integers

            # Add ID to the set
            unique_ids.add(obj_id)
            current_frame_ids.add(obj_id)  # Add to current frame's IDs

            # Draw bounding box for tracked objects
            cornerRect(img, (x1, y1, x2 - x1, y2 - y1), l=15, t=2, colorR=(0, 255, 0))  # Green for tracked objects

        # Remove IDs not present in the current frame
        unique_ids = unique_ids.intersection(current_frame_ids)

        # Display the current number of people (size of unique_ids set)
        cvzone.putTextRect(
            img,
            f'Number of People: {len(unique_ids)}',  # Display the count of unique IDs
            (50, 100),  # Position at the top-left corner
            scale=1.5,  # Larger text scale for better visibility
            thickness=2,  # Bold text
            colorR=(0, 255, 255)  # Yellow text for count
        )

        # Check for crowd size warning
        if len(unique_ids) > 5:
            cvzone.putTextRect(
                img,
                "Warning: Large Crowd Detected!",  # Warning message
                (50, 50),  # Position on the screen
                scale=2,  # Large text scale for visibility
                thickness=3,  # Bold text
                colorR=(0, 0, 255)  # Red warning text
            )

    # Display the image with bounding boxes and warnings (no class or ID displayed)
    cv2.imshow("Crowd Detection", img)

    # Key controls
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):  # Quit the loop
        break
    elif key == ord('p'):  # Pause or resume the video
        paused = not paused

# Print all unique IDs at the end
print("All unique IDs detected:", unique_ids)

# Example for metrics (placeholder for actual ground truth and predictions)
y_test = []  # Replace with actual ground truth labels
y_pred = []  # Replace with actual predicted labels

# Assuming y_test and y_pred are filled with actual data
if y_test and y_pred:
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')  # Use 'binary' for binary classification
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    print(f"Accuracy: {accuracy}")
    print(f"Precision: {precision}")
    print(f"Recall: {recall}")
    print(f"F1 Score: {f1}")
    print("Confusion Matrix:\n", cm)

# Release resources
cap.release()
cv2.destroyAllWindows()
